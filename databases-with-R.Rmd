---
title: "introduction to databases (but with R)"
output: github_document
editor_options:
  chunk_output_type: console
---

## background

This document generally mirrors the SOS 598 RDM [introduction to databases](https://github.com/SOS598-RDM/rdm-databases) resource but adapts the workflow from using a database GUI (e.g., DB Browser) to R. Please see the aforementioned document for background and details.

## create a database and connect to it

We can create a new database and connect to it from within R. Additionally, we will instruct SQLite to recognize foreign keys.

```{r DB connect-DB, results="hide"}

con <- DBI::dbConnect(
  drv = RSQLite::SQLite(),
  dbname = "~/Desktop/stream-metabolism-R.sqlite"
)

DBI::dbExecute(con, "PRAGMA foreign_keys = ON;")
```

## add database structure and data

#### sonde events

With DB Browser, we were able to use an import wizard to create the `sonde_events` table and import the data in a single action with a subsequent step of adding the NOT NULL, PRIMARY KEY, and AUTOINCREMENT characteristics to the 'id' field of our table with DB Browser's modify table tool. However, functionality for modifying tables after they are created is limited with SQLite, particularly outside of a GUI environment like DB Browser. A better approach, and one that we need to use with R, is to set these features when the table is created. So, instead of a creating the table by importing them, we will pass an SQL statement to create the table with the appropriate characteristics, then insert the data with a separate SQL statement. We can use the dbWriteTable function to crudely but quickly load the sonde event data into a temporary table, then insert them from the temporary table to the `sonde_events table` with the appropriate formatting and structure.

### create our sonde events table

```{r create-sonde-events-table, results="hide"}

DBI::dbExecute(
  conn = con,
  statement = "
  CREATE TABLE `sonde_events` (
    `id`            INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,
    `site_id`       TEXT,
    `date`          TEXT,
    `instrument_id` TEXT,
    `K2_20`         REAL
    );"
)
```

### add sonde events data

Load the data into the R environment.
- Note that SQLite does not have a type DATE so we will convert the dates to character.
- Note that we will remove the `id` column from our data and instead use the autoincrementing value that SQLite will provide.

```{r load-sonde-events-data, results="hide"}

sondeEvents <- readr::read_csv(file = "data/sonde_events.csv") |>
  dplyr::mutate(date = as.character(date)) |>
  dplyr::select(-id)

```

Write the data in the R environment to our database.

```{r load-sonde-events-database, results="hide"}

DBI::dbWriteTable(
  conn = con, 
  name = "sonde_events",
  value = sondeEvents,
  row.names = FALSE,
  overwrite = FALSE,
  append = TRUE,
  col.names = c(site_id, date, instrument_id, K2_20)
) 

```

#### sonde data

create our sonde data table:

```{r create-sonde-data-table, results="hide"}

DBI::dbExecute(
  conn = con,
  statement = "
  CREATE TABLE `sonde_data` (
    `sonde_event_id`  INTEGER NOT NULL,
    `Date`            TEXT NOT NULL,
    `Time`            TEXT NOT NULL,
    `Temp`            DOUBLE,
    `SpCond`          REAL,
    `DO`              REAL,
    PRIMARY KEY (`sonde_event_id`, `Date`, `Time`)
    FOREIGN KEY (`sonde_event_id`) REFERENCES sonde_events(`id`)
    );"
)
```

We need to add the sonde data to our database. Because we are now in a scripting environment, we can develop tools and approaches to automate some of these processes. For example, we can start with a function that will add data to our `sonde_data` table. This function formats data and adds the content to a temporary table.

Unlike the sonde events where we added the data directly to the table, for the sonde data, we will write the data to a temporary table in SQLite then insert the data into the `sonde_data` table from the temporary table within SQLite. This is not really necessary, and we could just append sonde data as we did with sonde event data but this is another way to address the data insert, and, in fact, may be necessary when you need to join data in order to insert it.

```{r read-insert-helper-function}

tempTableData <- function(
  dataFile,
  overWrite = FALSE
  ) {

  # set append argument to dbWriteTable based on user input ~ overwrite
  if (overWrite == FALSE) { 

    setAppend = TRUE

  } else {

    setAppend = FALSE

  }

  # read that data file
  dataFile <- readr::read_csv(dataFile) |> 
  dplyr::mutate(
    Date = as.character(Date),
    Time = as.character(Time)
  )

  # write specified data to tempTable
  DBI::dbWriteTable(
    conn = con, 
    name = "tempTable",
    value = dataFile,
    row.names = FALSE,
    temporary = FALSE,
    overwrite = overWrite,
    append = setAppend
  )
}

```

use the script to load sonde event data 1 through 4:

```{r load-sonde-data-1:4}

# list data resources to load
dataFiles <- list(
  "data/sonde_data_1_3.csv",
  "data/sonde_data_4.csv"
)

# use the tempTableData function to load the data
lapply(dataFiles, tempTableData, overWrite = FALSE)
```

insert the data into the `sonde_data` table by selecting the data inserted into
the temporary table:

```{r insert-sonde-data}

DBI::dbExecute(
  conn = con,
  statement = "
  INSERT INTO sonde_data(
    sonde_event_id,
    Date,
    Time,
    Temp,
    SpCond,
    DO) 
  SELECT
    sonde_event_id, 
    Date, 
    Time, 
    Temp, 
    SpCond,
    DO 
  FROM tempTable
  ;"
)
```

Since there is not a sonde event 5 in our `sonde_events` table, we need to add
it before we can load event 5 data into the sonde_data table.

```{r add-sonde-event-five}

DBI::dbExecute(
  conn = con,
  statement = "
  INSERT INTO sonde_events
  (
    site_id,  
    date,
    instrument_id,
    K2_20
  )
  VALUES
  (
    'new site',
    '2021-03-20',
    'yellow',
    60.42
  );"
)
```

Now that there is an event 5 in our `sonde_events` table, we can add data from sonde event 5 to our `sonde_data` table. This chunk will load the event 5 sonde data into our temporary table.

```{r load-sonde-data-5}

dataFiles <- list("data/sonde_data_5.csv")

lapply(dataFiles, tempTableData, overWrite = TRUE)
```

I can then insert the data into the `sonde_data` table from the temporary table by rerunning the code in the `insert-sonde-data` chunk that we employed earlier for this purpose.

```{r insert-sonde-data-5, ref.label="insert-sonde-data"}
```

## extract data from the database

There are several approaches that we can employ to access data in our database. One is to use SQL statements as we have done to create and populate our database. Another is to use dplyr/dbplyr functionality so that we can access the data using dplyr syntax, which it will convert to SQL for us.

get the first ten rows from the `sonde_data` table with SQL:

```{r sonde-data-head}

DBI::dbGetQuery(
  conn = con,
  statement = "
  SELECT *
    FROM sonde_data
  LIMIT 10;"
)

```

We can assign the results of that query as an object in our R environment.

```{r sonde-data-head-assignment}

sonde_data_top <- DBI::dbGetQuery(
  conn = con,
  statement = "
  SELECT *
    FROM sonde_data
  LIMIT 10;
  "
)

```

with dplyr:

create a pointer to the `sonde_events` table in our database

```{r sonde_events-db}

event_db <- dplyr::tbl(src = con, "sonde_events")
```

we can then access the information in the `sonde_events` table by referencing the pointer

use the `show_query()` function to transate the dplyr statement to SQL

```{r sonde-events-select-show-query}

event_db |> 
  dplyr::select(everything()) |> 
  dplyr::show_query()
```

example: select all data from the `sonde_events` table

```{r sonde-events-select-all}

event_db |>
  dplyr::select(dplyr::everything())
```

example: assign results of select all data from the `sonde_events` table to an object in our R environment

```{r sonde-events-select-all-assignment}

sondeevent <- event_db |>
  dplyr::select(everything()) |>
  dplyr::collect()
```

Usually we want to use certain search criteria. Note the difference between the SQL and dplyr syntax to harvest the Date and DO fields from the `sonde_data` table that were collected on the 15th of August.

*SQL*

```{r select-SQL}

DBI::dbGetQuery(
  conn = con,
  statement = "
  SELECT
    Date,
    DO
  FROM sonde_data 
  WHERE strftime('%m', Date) = '08' AND strftime('%d', Date) = '15'
  LIMIT 10;"
)
```

*dplyr*

```{r sonde-data-db}

sondedata_db <- dplyr::tbl(
  src = con,
  "sonde_data"
)
```

```{r select-dplyr}

sondedata_db |>
  dplyr::select(Date, DO) |>
  dplyr::collect() |>
  dplyr::mutate(Date = as.Date(Date, format = "%Y-%m-%d")) |> 
  dplyr::filter(lubridate::month(Date) == 8 & lubridate::day(Date) == 15) |> 
  head(n = 10)
```

We can group results based on data features that can be binned, this is particularly useful for aggregate functions. The query below extracts the minimum and maximum dissolved oxygen (DO) values for each sonde event.

```{r sonde-data-grouping}

sondedata_db |>
  dplyr::select(everything()) |>
  dplyr::group_by(sonde_event_id) |> 
  dplyr::summarise(
    min_DO = min(DO, na.rm = TRUE),
    max_DO = max(DO, na.rm = TRUE)
  ) 
```

The ability to link information in our tables is a core features of databases. We do this with **JOINs**.

For example, incorporate site_id from the `sonde_events` table into a query of temperature and dissolved oxygen from `sonde_data`:

```{r inner-join}

sondedata_db |> 
  dplyr::select(sonde_event_id, Temp, DO) |> 
  dplyr::inner_join(event_db |> dplyr::select(id, site_id), by = c("sonde_event_id" = "id")) |> 
  dplyr::select(site_id, Temp, DO) |> 
  head(n = 10)
```

For example, find the minimum and maximum dissolved oxgyen values for each sonde_event as per above but this time include the site and the K2_20 from the sonde_events table:

```{r inner-join-aggregation}

sondedata_db |>
  dplyr::select(everything()) |>
  dplyr::group_by(sonde_event_id) |> 
  dplyr::summarise(
    min_DO = min(DO, na.rm = TRUE),
    max_DO = max(DO, na.rm = TRUE)
  ) |> 
  dplyr::inner_join(event_db |> dplyr::select(id, site_id), by = c("sonde_event_id" = "id"))
```

## databases? eh, whatevs

join the sonde data and sonde events data using the sonde_event_id:

```{r join-with-key, message=FALSE}

readr::read_csv(file = "data/sonde_data_1_3.csv") |> 
  dplyr::inner_join(readr::read_csv(file = "data/sonde_events.csv") |> dplyr::select(-date), by = c("sonde_event_id" = "id")) |> 
  View("joinWithKey")
```

further, we do not really need a key, but we need to store more information in our tables without it:

```{r join-sans-key, message=FALSE}

readr::read_csv("data/sonde_data_1_3.csv") |> 
  dplyr::mutate(
    site_id = dplyr::case_when(
      sonde_event_id == 1 ~ "GB",
      sonde_event_id == 2 ~ "GB",
      sonde_event_id == 3 ~ "SC"),
    instrument_id = dplyr::case_when(
      sonde_event_id == 1 ~ "black",
      sonde_event_id == 2 ~ "red",
      sonde_event_id == 3 ~ "green")
    ) |> 
dplyr::inner_join(readr::read_csv("data/sonde_events.csv") |> dplyr::select(-date), by = c("site_id", "instrument_id")) |> 
View("joinSansKey")
```
